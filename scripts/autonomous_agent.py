#!/usr/bin/env python3
"""
autonomous_agent.py - æ¯æœãƒªã‚µãƒ¼ãƒæŠ•ç¨¿ãƒ‡ãƒ¼ãƒ¢ãƒ³ (Phase 2)

ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«: æ¯æœ 08:00
ãƒ•ãƒ­ãƒ¼: observe â†’ think â†’ act â†’ reflect â†’ notify

LLMï¼ˆãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ§‹æˆ - Issue #1ï¼‰:
  - Ollama / qwen3:8b : è»½é‡ã‚¿ã‚¹ã‚¯å„ªå…ˆï¼ˆãƒ†ãƒ¼ãƒé¸å®šãƒ»è‡ªå·±è©•ä¾¡ï¼‰
  - claude-haiku-4-5  : Ollamaä¸å¯æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
  - claude-sonnet-4-6 : è¤‡é›‘ã‚¿ã‚¹ã‚¯å°‚ç”¨ï¼ˆè¨˜äº‹è‰ç¨¿ç”Ÿæˆï¼‰

å®‰å…¨è¨­è¨ˆ:
  - æ—¥æ¬¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ä¸Šé™: 50å›
  - å…¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’Discordé€šçŸ¥
  - ç ´å£Šçš„æ“ä½œï¼ˆgit push, file deleteç­‰ï¼‰ã¯å®Ÿè¡Œã—ãªã„

ãƒãƒ£ãƒ³ãƒãƒ«:
  - hub-autonomous (DISCORD_CHANNEL_ID)    : ãƒ¡ã‚¤ãƒ³ã‚¢ã‚¯ã‚·ãƒ§ãƒ³çµæœã®é€šçŸ¥
  - agent-diary   (DIARY_CHANNEL_ID)       : æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ãƒ»å†…çœãƒ»ç‹¬ã‚Šè¨€ï¼ˆIssue #9ï¼‰
  - agent-chat    (AGENT_CHAT_CHANNEL_ID)  : Adminç›´æ¥å¯¾è©±ï¼ˆqwen3:8bå¿œç­”ã€Issue #18ï¼‰
"""

import os
import glob
import json
import logging
from datetime import datetime, date

import signal
import threading
from http.server import BaseHTTPRequestHandler, HTTPServer

import httpx
import anthropic
from apscheduler.schedulers.blocking import BlockingScheduler
from apscheduler.executors.pool import ThreadPoolExecutor

# â”€â”€â”€ è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
HUB_API_URL = os.getenv("HUB_API_URL", "http://localhost:8080")
DISCORD_CHANNEL = os.getenv("DISCORD_CHANNEL_ID", "1475499842800451616")   # hub-autonomous
DIARY_CHANNEL   = os.getenv("DIARY_CHANNEL_ID",   "1475552269222154312")   # agent-diary (Issue #9)
CHAT_CHANNEL    = os.getenv("AGENT_CHAT_CHANNEL_ID", "1475867265110114379") # agent-chat (Issue #18)
AGENT_NAME = "autonomous-agent"
MAX_DAILY_ACTIONS = 50
AGENT_CHAT_DIR = "/tmp/autonomous-agent-chat"  # Go APIãŒã“ã“ã«chatãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ›¸ãè¾¼ã‚€
AGENT_CHAT_PORT = int(os.getenv("AGENT_CHAT_PORT", "18400"))

# Ollamaè¨­å®šï¼ˆIssue #1: ãƒ­ãƒ¼ã‚«ãƒ«LLMï¼‰
OLLAMA_URL   = os.getenv("OLLAMA_URL",   "http://localhost:11434")
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "qwen3:8b")
OLLAMA_MODEL_CHAT = os.getenv("OLLAMA_MODEL_CHAT", "zono-agent:latest")

# ãƒªã‚µãƒ¼ãƒãƒˆãƒ”ãƒƒã‚¯ï¼ˆæ›œæ—¥ã§äº¤äº’ï¼‰
# æœˆãƒ»æ°´ãƒ»é‡‘ = Web3, ç«ãƒ»æœ¨ãƒ»åœŸ = AI, æ—¥ = ä¸¡æ–¹
TOPICS_WEB3 = "Web3 / DeFi / HyperLiquid / ã‚ªãƒ³ãƒã‚§ãƒ¼ãƒ³åˆ†æ"
TOPICS_AI   = "AI / LLM / ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæŠ€è¡“ / Claude / RAG"

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
)
log = logging.getLogger(__name__)

client = anthropic.Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
action_count = 0


# â”€â”€â”€ ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_today_topics() -> str:
    """æ›œæ—¥ã«å¿œã˜ã¦ãƒªã‚µãƒ¼ãƒãƒˆãƒ”ãƒƒã‚¯ã‚’æ±ºå®šï¼ˆ0=æœˆ, 6=æ—¥ï¼‰"""
    weekday = date.today().weekday()
    if weekday in (0, 2, 4):   # æœˆãƒ»æ°´ãƒ»é‡‘
        return TOPICS_WEB3
    elif weekday in (1, 3, 5): # ç«ãƒ»æœ¨ãƒ»åœŸ
        return TOPICS_AI
    else:                       # æ—¥æ›œ
        return f"{TOPICS_WEB3} / {TOPICS_AI}"


def notify_discord(message: str, is_alert: bool = False) -> None:
    """hub-autonomous ãƒãƒ£ãƒ³ãƒãƒ«ã«ã‚¢ã‚¯ã‚·ãƒ§ãƒ³çµæœã‚’é€šçŸ¥"""
    try:
        httpx.post(
            f"{HUB_API_URL}/api/v1/discord/reply",
            json={
                "channel_id": DISCORD_CHANNEL,
                "message": message,
                "sender_name": AGENT_NAME,
            },
            timeout=10,
        )
    except Exception as e:
        log.warning(f"Discordé€šçŸ¥å¤±æ•—: {e}")


DIARY_EMOJI = {
    "observe":  "ğŸ‘€",
    "think":    "ğŸ¤”",
    "act":      "âœï¸",
    "reflect":  "ğŸ“",
    "daily":    "ğŸŒ™",
    "startup":  "ğŸ¤–",
    "error":    "âš ï¸",
}

def post_diary(content: str, step: str = "think") -> None:
    """agent-diary ãƒãƒ£ãƒ³ãƒãƒ«ã«æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ãƒ»å†…çœã‚’æŠ•ç¨¿ï¼ˆIssue #9ï¼‰"""
    emoji = DIARY_EMOJI.get(step, "ğŸ’­")
    try:
        httpx.post(
            f"{HUB_API_URL}/api/v1/discord/reply",
            json={
                "channel_id": DIARY_CHANNEL,
                "message": f"{emoji} **[{step}]** {content}",
                "sender_name": AGENT_NAME,
            },
            timeout=10,
        )
        log.debug(f"Diary posted [{step}]: {content[:60]}")
    except Exception as e:
        log.warning(f"DiaryæŠ•ç¨¿å¤±æ•—: {e}")


# â”€â”€â”€ ãƒ­ãƒ¼ã‚«ãƒ«LLMï¼ˆOllamaï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class LocalLLM:
    """Ollama ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆIssue #1ï¼‰"""

    @staticmethod
    def is_available() -> bool:
        """Ollamaã‚µãƒ¼ãƒãƒ¼ãŒç¨¼åƒä¸­ã‹ç¢ºèª"""
        try:
            r = httpx.get(f"{OLLAMA_URL}/api/tags", timeout=3)
            return r.status_code == 200
        except Exception:
            return False

    @staticmethod
    def generate(prompt: str, max_tokens: int = 500) -> str:
        """ãƒ­ãƒ¼ã‚«ãƒ«LLMï¼ˆqwen3:8bï¼‰ã§æ¨è«–ã€‚think:false ã§ã‚·ãƒ³ã‚­ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ç„¡åŠ¹åŒ–"""
        resp = httpx.post(
            f"{OLLAMA_URL}/api/generate",
            json={
                "model": OLLAMA_MODEL,
                "prompt": prompt,
                "stream": False,
                "think": False,   # qwen3ã®ã‚·ãƒ³ã‚­ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ã‚’ç„¡åŠ¹åŒ–ï¼ˆé«˜é€ŸåŒ–ï¼‰
                "options": {"num_predict": max_tokens, "temperature": 0.7},
            },
            timeout=120,
        )
        resp.raise_for_status()
        return resp.json()["response"].strip()


def count_action(label: str) -> bool:
    """ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã€‚ä¸Šé™è¶…éã§Falseã‚’è¿”ã™"""
    global action_count
    action_count += 1
    if action_count > MAX_DAILY_ACTIONS:
        log.warning(f"æ—¥æ¬¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ä¸Šé™({MAX_DAILY_ACTIONS})è¶…éã€‚ã‚¹ã‚­ãƒƒãƒ—: {label}")
        notify_discord(f"âš ï¸ æ—¥æ¬¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ä¸Šé™åˆ°é”ã€‚æœ¬æ—¥ã®å‡¦ç†ã‚’åœæ­¢ã—ã¾ã™ã€‚")
        return False
    log.info(f"[action {action_count}/{MAX_DAILY_ACTIONS}] {label}")
    return True


# â”€â”€â”€ observe â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def fetch_hn_top(n: int = 10) -> list[dict]:
    """Hacker News Top Stories ã‚’å–å¾—"""
    try:
        r = httpx.get(
            "https://hacker-news.firebaseio.com/v0/topstories.json",
            timeout=10,
        )
        ids = r.json()[:n]
        stories = []
        for sid in ids:
            item = httpx.get(
                f"https://hacker-news.firebaseio.com/v0/item/{sid}.json",
                timeout=5,
            ).json()
            if item and item.get("title"):
                stories.append({
                    "title": item.get("title", ""),
                    "url": item.get("url", ""),
                    "score": item.get("score", 0),
                })
        return stories
    except Exception as e:
        log.warning(f"HNå–å¾—å¤±æ•—: {e}")
        return []


def fetch_github_trending(topic_hint: str) -> list[dict]:
    """GitHub Trending ã«è¿‘ã„æƒ…å ±ã‚’ GitHub Search API ã§ä»£æ›¿å–å¾—"""
    # GitHubã®Trending APIã¯éå…¬å¼ã®ãŸã‚ã€éå»7æ—¥ã®é«˜ã‚¹ã‚¿ãƒ¼ãƒªãƒã‚¸ãƒˆãƒªã§ä»£æ›¿
    query = "ai llm agent" if "AI" in topic_hint else "defi web3 blockchain"
    try:
        r = httpx.get(
            "https://api.github.com/search/repositories",
            params={
                "q": f"{query} created:>2026-02-17",
                "sort": "stars",
                "order": "desc",
                "per_page": 5,
            },
            headers={"Accept": "application/vnd.github+json"},
            timeout=10,
        )
        repos = r.json().get("items", [])
        return [
            {
                "name": repo["full_name"],
                "description": repo.get("description", ""),
                "stars": repo["stargazers_count"],
                "url": repo["html_url"],
            }
            for repo in repos
        ]
    except Exception as e:
        log.warning(f"GitHub trendingå–å¾—å¤±æ•—: {e}")
        return []


def observe(topics: str) -> dict:
    """ç’°å¢ƒã‚’è¦³å¯Ÿã—ã¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åé›†"""
    log.info("=== [observe] ãƒˆãƒ¬ãƒ³ãƒ‰åé›†é–‹å§‹ ===")
    hn_stories = fetch_hn_top(10)
    gh_repos = fetch_github_trending(topics)
    context = {
        "date": date.today().isoformat(),
        "topics": topics,
        "hn_stories": hn_stories,
        "gh_repos": gh_repos,
    }
    log.info(f"HN: {len(hn_stories)}ä»¶, GitHub: {len(gh_repos)}ä»¶")

    # agent-diary: è¦³å¯Ÿãƒ­ã‚°
    hn_titles = ", ".join(s["title"][:30] for s in hn_stories[:3]) if hn_stories else "ãªã—"
    gh_names  = ", ".join(r["name"].split("/")[-1] for r in gh_repos[:3]) if gh_repos else "ãªã—"
    post_diary(
        f"ãƒˆãƒ¬ãƒ³ãƒ‰åé›†å®Œäº†\nãƒˆãƒ”ãƒƒã‚¯: {topics}\n"
        f"HNæ³¨ç›®: {hn_titles}\nGitHubæ³¨ç›®: {gh_names}",
        step="observe",
    )
    return context


# â”€â”€â”€ think â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def think(context: dict) -> str:
    """ãƒ†ãƒ¼ãƒé¸å®š: Ollamaå„ªå…ˆã€Claude Haikuãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆIssue #1ï¼‰"""
    if not count_action("think: ãƒ†ãƒ¼ãƒé¸å®š"):
        return ""

    prompt = f"""ä»Šæ—¥ã®ãƒªã‚µãƒ¼ãƒãƒ†ãƒ¼ãƒã‚’1ã¤é¸å®šã—ã¦ãã ã•ã„ã€‚

å¯¾è±¡ãƒˆãƒ”ãƒƒã‚¯: {context['topics']}
æ—¥ä»˜: {context['date']}

Hacker News ãƒˆãƒ¬ãƒ³ãƒ‰:
{json.dumps(context['hn_stories'], ensure_ascii=False, indent=2)}

GitHub æ³¨ç›®ãƒªãƒã‚¸ãƒˆãƒª:
{json.dumps(context['gh_repos'], ensure_ascii=False, indent=2)}

ä¸Šè¨˜ã‚’è¸ã¾ãˆã€Zennè¨˜äº‹ã¨ã—ã¦æœ€ã‚‚ä¾¡å€¤ãŒé«˜ã„ã¨æ€ã‚ã‚Œã‚‹ãƒ†ãƒ¼ãƒã‚’1è¡Œã§ç­”ãˆã¦ãã ã•ã„ã€‚
å½¢å¼: ã€Œãƒ†ãƒ¼ãƒ: <ãƒ†ãƒ¼ãƒå>ï¼ˆç†ç”±: <50å­—ä»¥å†…>ï¼‰ã€"""

    # Ollamaå„ªå…ˆ
    if LocalLLM.is_available():
        log.info(f"=== [think] ãƒ†ãƒ¼ãƒé¸å®š (ollama: {OLLAMA_MODEL}) ===")
        try:
            theme = LocalLLM.generate(prompt, max_tokens=200)
            log.info(f"é¸å®šãƒ†ãƒ¼ãƒ (Ollama): {theme}")
            post_diary(f"{theme}", step="think")
            return theme
        except Exception as e:
            log.warning(f"Ollamaå¤±æ•—ã€Claude Haikuã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {e}")

    # Claude Haiku ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    log.info("=== [think] ãƒ†ãƒ¼ãƒé¸å®š (claude-haiku-4-5) ===")
    resp = client.messages.create(
        model="claude-haiku-4-5-20251001",
        max_tokens=200,
        messages=[{"role": "user", "content": prompt}],
    )
    theme = resp.content[0].text.strip()
    log.info(f"é¸å®šãƒ†ãƒ¼ãƒ (Claude): {theme}")

    # agent-diary: ãƒ†ãƒ¼ãƒé¸å®šã®æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹
    post_diary(f"{theme}", step="think")
    return theme


# â”€â”€â”€ act â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def act(theme: str, context: dict) -> str:
    """Claude Sonnet ã§ Zenn è¨˜äº‹è‰ç¨¿ã‚’ç”Ÿæˆ"""
    if not theme or not count_action("act: è¨˜äº‹è‰ç¨¿ç”Ÿæˆ"):
        return ""

    log.info("=== [act] è¨˜äº‹è‰ç¨¿ç”Ÿæˆ (claude-sonnet-4-6) ===")
    prompt = f"""ä»¥ä¸‹ã®ãƒ†ãƒ¼ãƒã§ZennæŠ€è¡“è¨˜äº‹ã®è‰ç¨¿ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ãƒ†ãƒ¼ãƒ: {theme}
æ—¥ä»˜: {context['date']}

å‚è€ƒæƒ…å ±:
{json.dumps(context['hn_stories'][:5], ensure_ascii=False, indent=2)}

è¦ä»¶:
- Zennã®markdownå½¢å¼ï¼ˆfrontmatterä»˜ãï¼‰
- æ–‡å­—æ•°: 1500ã€œ2500å­—ç¨‹åº¦
- å¯¾è±¡èª­è€…: ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ï¼ˆWeb3/AIé ˜åŸŸï¼‰
- ç‹¬è‡ªã®è€ƒå¯Ÿãƒ»æ„è¦‹ã‚’å«ã‚ã‚‹
- published: false ã§ä¸‹æ›¸ãçŠ¶æ…‹ã«

frontmatterã®topicsã¯å®Ÿéš›ã®Zennã‚¿ã‚°åï¼ˆè‹±å°æ–‡å­—ï¼‰ã‚’ä½¿ã†ã“ã¨ã€‚"""

    resp = client.messages.create(
        model="claude-sonnet-4-6",
        max_tokens=4096,
        messages=[{"role": "user", "content": prompt}],
    )
    draft = resp.content[0].text.strip()
    log.info(f"è‰ç¨¿ç”Ÿæˆå®Œäº†: {len(draft)}æ–‡å­—")
    return draft


# â”€â”€â”€ reflect â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def reflect(draft: str, theme: str) -> dict:
    """è‰ç¨¿ã®å“è³ªã‚’è‡ªå·±è©•ä¾¡: Ollamaå„ªå…ˆã€Claude Haikuãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆIssue #1ï¼‰"""
    if not draft or not count_action("reflect: è‡ªå·±è©•ä¾¡"):
        return {"score": 0, "comment": "ã‚¹ã‚­ãƒƒãƒ—"}

    # Ollamaç”¨ã¯çŸ­ç¸®ç‰ˆï¼ˆ500å­—ï¼‰ã€Claudeç”¨ã¯ãƒ•ãƒ«ç‰ˆï¼ˆ2000å­—ï¼‰
    draft_short = draft[:500]
    draft_full  = draft[:2000]

    prompt_ollama = f"""ä»¥ä¸‹ã®Zennè¨˜äº‹è‰ç¨¿ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

ãƒ†ãƒ¼ãƒ: {theme}

---
{draft_short}
---

ä»¥ä¸‹ã®è¦³ç‚¹ã§100ç‚¹æº€ç‚¹ã§æ¡ç‚¹ã—ã€JSONå½¢å¼ã®ã¿ã§è¿”ã—ã¦ãã ã•ã„:
å½¢å¼: {{"coherence": N, "originality": N, "readability": N, "accuracy": N, "total": N, "comment": "ä¸€è¨€ã‚³ãƒ¡ãƒ³ãƒˆ"}}"""

    prompt_claude = f"""ä»¥ä¸‹ã®Zennè¨˜äº‹è‰ç¨¿ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

ãƒ†ãƒ¼ãƒ: {theme}

---
{draft_full}
---

ä»¥ä¸‹ã®è¦³ç‚¹ã§100ç‚¹æº€ç‚¹ã§æ¡ç‚¹ã—ã€JSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„:
- coherence: è«–ç†çš„ä¸€è²«æ€§ï¼ˆ0-30ï¼‰
- originality: ç‹¬è‡ªæ€§ãƒ»æ–°è¦æ€§ï¼ˆ0-30ï¼‰
- readability: èª­ã¿ã‚„ã™ã•ï¼ˆ0-20ï¼‰
- accuracy: æŠ€è¡“çš„æ­£ç¢ºæ€§ï¼ˆ0-20ï¼‰

å½¢å¼: {{"coherence": N, "originality": N, "readability": N, "accuracy": N, "total": N, "comment": "ä¸€è¨€ã‚³ãƒ¡ãƒ³ãƒˆ"}}"""

    text = ""
    # Ollamaå„ªå…ˆï¼ˆçŸ­ç¸®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§é«˜é€Ÿè©•ä¾¡ï¼‰
    if LocalLLM.is_available():
        log.info(f"=== [reflect] è‡ªå·±è©•ä¾¡ (ollama: {OLLAMA_MODEL}) ===")
        try:
            text = LocalLLM.generate(prompt_ollama, max_tokens=150)
            log.info(f"è‡ªå·±è©•ä¾¡å¿œç­” (Ollama): {text[:100]}")
        except Exception as e:
            log.warning(f"Ollamaå¤±æ•—ã€Claude Haikuã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {e}")
            text = ""

    # Claude Haiku ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    if not text:
        log.info("=== [reflect] è‡ªå·±è©•ä¾¡ (claude-haiku-4-5) ===")
        resp = client.messages.create(
            model="claude-haiku-4-5-20251001",
            max_tokens=300,
            messages=[{"role": "user", "content": prompt_claude}],
        )
        text = resp.content[0].text.strip()

    try:
        # JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡º
        start = text.find("{")
        end = text.rfind("}") + 1
        result = json.loads(text[start:end])
    except Exception:
        result = {"total": 0, "comment": "è©•ä¾¡ãƒ‘ãƒ¼ã‚¹å¤±æ•—", "raw": text}
    log.info(f"è‡ªå·±è©•ä¾¡: {result}")

    # agent-diary: å†…çœãƒ­ã‚°
    total   = result.get("total", "?")
    comment = result.get("comment", "")
    coherence    = result.get("coherence", "?")
    originality  = result.get("originality", "?")
    readability  = result.get("readability", "?")
    accuracy     = result.get("accuracy", "?")
    post_diary(
        f"è‡ªå·±è©•ä¾¡ã‚¹ã‚³ã‚¢: {total}/100\n"
        f"å†…è¨³: ä¸€è²«æ€§{coherence} / ç‹¬è‡ªæ€§{originality} / èª­ã¿ã‚„ã™ã•{readability} / æ­£ç¢ºæ€§{accuracy}\n"
        f"æ‰€æ„Ÿ: {comment}",
        step="reflect",
    )
    return result


# â”€â”€â”€ agent-chat ãƒãƒ³ãƒ‰ãƒ©ï¼ˆIssue #18, #31ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def judge_importance(sender: str, message: str, response: str) -> float:
    """Ollamaã§ä¼šè©±ã®é‡è¦åº¦ã‚’1-10ã§åˆ¤å®š"""
    prompt = f"""ä»¥ä¸‹ã®ä¼šè©±ã®é‡è¦åº¦ã‚’1ã€œ10ã§è©•ä¾¡ã—ã¦ãã ã•ã„ï¼ˆæ•°å­—ã®ã¿è¿”ç­”ï¼‰ã€‚
é‡è¦åº¦ãŒé«˜ã„æ¡ä»¶: æŠ€è¡“çš„ãªæ´å¯Ÿãƒ»é‡è¦ãªæ±ºå®šãƒ»å€‹äººçš„ãªé–¢å¿ƒäº‹ãƒ»å°†æ¥å‚ç…§ã™ã‚‹å¯èƒ½æ€§

ä¼šè©±:
[{sender}]: {message}
[å¿œç­”]: {response[:300]}

é‡è¦åº¦ï¼ˆ1ã€œ10ã®æ•´æ•°ã®ã¿ï¼‰:"""
    try:
        score_text = LocalLLM.generate(prompt, max_tokens=5)
        return min(10.0, max(1.0, float(score_text.strip()[:3])))
    except Exception:
        return 5.0


def chat_handler(message: str, sender: str, reply_channel_id: str) -> None:
    """agent-chat ãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ zono-agent:latest ã§å‡¦ç†ã—ã¦è¿”ä¿¡ï¼ˆIssue #31ï¼‰"""
    log.info(f"ğŸ’¬ chat_handler: {sender}: {message[:80]}")

    prompt = (
        f"{sender} ã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå±Šãã¾ã—ãŸã€‚\n\n"
        f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:\n{message}\n\n"
        "æ—¥æœ¬èªã§ç°¡æ½”ã‹ã¤çš„ç¢ºã«å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    )

    try:
        if LocalLLM.is_available():
            resp = httpx.post(
                f"{OLLAMA_URL}/api/generate",
                json={
                    "model": OLLAMA_MODEL_CHAT,
                    "prompt": prompt,
                    "stream": False,
                    "think": False,
                    "options": {"num_predict": 800, "temperature": 0.7},
                },
                timeout=120,
            )
            resp.raise_for_status()
            response = resp.json()["response"].strip()
            llm_label = OLLAMA_MODEL_CHAT
        else:
            # Claude Haiku ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            resp = client.messages.create(
                model="claude-haiku-4-5-20251001",
                max_tokens=800,
                messages=[{"role": "user", "content": prompt}],
            )
            response = resp.content[0].text.strip()
            llm_label = "Claude Haiku (fallback)"
    except Exception as e:
        log.error(f"chat_handler LLM error: {e}")
        response = f"âš ï¸ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
        llm_label = "error"

    # agent-chat ãƒãƒ£ãƒ³ãƒãƒ«ã«è¿”ä¿¡
    try:
        httpx.post(
            f"{HUB_API_URL}/api/v1/discord/reply",
            json={
                "channel_id": reply_channel_id,
                "message": f"ğŸ’¬ [{llm_label}] {response}",
                "sender_name": AGENT_NAME,
            },
            timeout=10,
        )
    except Exception as e:
        log.warning(f"chat_handler Discordè¿”ä¿¡å¤±æ•—: {e}")

    post_diary(f"**{sender}**: {message[:100]}\nâ†’ {response[:200]}", step="think")

    # MemoryManager: importanceè‡ªå‹•åˆ¤å®šã—ã¦ChromaDBä¿å­˜
    try:
        from memory_manager import MemoryManager
        importance = judge_importance(sender, message, response)
        log.info(f"chat importance: {importance}")
        mm = MemoryManager()
        saved = mm.add_chat(sender=sender, message=message, response=response, importance=importance)
        if saved:
            log.info(f"chat saved to agent_memory (importance={importance})")
    except Exception as e:
        log.warning(f"memory_manager.add_chatå¤±æ•—: {e}")


class ChatHTTPHandler(BaseHTTPRequestHandler):
    """POST /chat ã‚’å—ã‘ä»˜ã‘ã¦chat_handlerã«å§”è­²ã™ã‚‹HTTPãƒãƒ³ãƒ‰ãƒ©ï¼ˆIssue #31ï¼‰"""

    def do_POST(self):
        if self.path != "/chat":
            self.send_response(404)
            self.end_headers()
            return
        length = int(self.headers.get("Content-Length", 0))
        body = json.loads(self.rfile.read(length))
        sender = body.get("sender", "Admin")
        content = body.get("content", "")
        channel_id = body.get("channel_id", CHAT_CHANNEL)
        self.send_response(200)
        self.end_headers()
        self.wfile.write(b"ok")
        # åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å‡¦ç†ï¼ˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å³è¿”ã™ï¼‰
        threading.Thread(target=chat_handler, args=(content, sender, channel_id), daemon=True).start()

    def log_message(self, format, *args):
        log.debug(f"ChatHTTP: {format % args}")


def start_chat_http_server():
    """ãƒãƒ£ãƒƒãƒˆHTTPã‚µãƒ¼ãƒãƒ¼ã‚’ãƒ‡ãƒ¼ãƒ¢ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã§èµ·å‹•"""
    server = HTTPServer(("localhost", AGENT_CHAT_PORT), ChatHTTPHandler)
    log.info(f"Chat HTTP server listening on localhost:{AGENT_CHAT_PORT}")
    t = threading.Thread(target=server.serve_forever, daemon=True)
    t.start()
    return server


def poll_chat_messages() -> None:
    """agent-chat ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æœªå‡¦ç†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†ã™ã‚‹ï¼ˆAPSchedulerå®šæœŸã‚¸ãƒ§ãƒ–ï¼‰"""
    if not os.path.isdir(AGENT_CHAT_DIR):
        return

    files = sorted(glob.glob(f"{AGENT_CHAT_DIR}/chat-*.json"))
    if not files:
        return

    log.info(f"ğŸ’¬ chat poll: {len(files)} ä»¶ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸")
    for fpath in files:
        try:
            with open(fpath, "r", encoding="utf-8") as f:
                data = json.load(f)
            sender     = data.get("sender", "Admin")
            content    = data.get("content", "")
            channel_id = data.get("channel_id", CHAT_CHANNEL)

            if content:
                chat_handler(content, sender, channel_id)

            os.remove(fpath)
        except Exception as e:
            log.error(f"chat poll error ({fpath}): {e}")
            try:
                os.remove(fpath)   # å£Šã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã¯å‰Šé™¤ã—ã¦é€²ã‚€
            except Exception:
                pass


# â”€â”€â”€ ãƒ¡ã‚¤ãƒ³ã‚¿ã‚¹ã‚¯ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def daily_research():
    """æ¯æœ08:00ã«å®Ÿè¡Œã•ã‚Œã‚‹ãƒ¡ã‚¤ãƒ³ã‚¿ã‚¹ã‚¯ã€‚
    å…¨ä½“ã‚’try/exceptã§å›²ã¿ã€æœªå‡¦ç†ä¾‹å¤–ã«ã‚ˆã‚‹ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ—ãƒ¼ãƒ«å´©å£Šã‚’é˜²æ­¢ã€‚"""
    global action_count
    try:
        action_count = 0  # æ—¥æ¬¡ãƒªã‚»ãƒƒãƒˆ

        today = date.today().isoformat()
        topics = get_today_topics()
        log.info(f"=== æ¯æœãƒªã‚µãƒ¼ãƒé–‹å§‹: {today} / ãƒ†ãƒ¼ãƒ: {topics} ===")
        notify_discord(f"ğŸŒ… æ¯æœãƒªã‚µãƒ¼ãƒé–‹å§‹\næ—¥ä»˜: {today}\nãƒˆãƒ”ãƒƒã‚¯: {topics}")

        # observe
        context = observe(topics)

        # think
        theme = think(context)
        if not theme:
            notify_discord("âš ï¸ ãƒ†ãƒ¼ãƒé¸å®šã«å¤±æ•—ã—ã¾ã—ãŸã€‚æœ¬æ—¥ã®å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚", is_alert=True)
            return

        # act
        draft = act(theme, context)
        if not draft:
            notify_discord("âš ï¸ è¨˜äº‹è‰ç¨¿ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚", is_alert=True)
            return

        # reflect
        evaluation = reflect(draft, theme)

        # MemoryManager: ãƒªã‚µãƒ¼ãƒãƒ­ã‚°ã‚’è“„ç©
        score = evaluation.get("total", "?")
        try:
            from memory_manager import MemoryManager
            mm = MemoryManager()
            # reflect scoreã‚’importanceã«å¤‰æ›ï¼ˆ100ç‚¹æº€ç‚¹â†’10ç‚¹æº€ç‚¹ï¼‰
            importance = min(10.0, max(1.0, score / 10.0)) if isinstance(score, (int, float)) else 5.0
            mm.add_research(date=today, topic=topics, theme=theme, score=score if isinstance(score, (int, float)) else 0, summary=evaluation.get("comment", ""))
        except Exception as e:
            log.warning(f"memory_manager.add_researchå¤±æ•—: {e}")

        # notify
        comment = evaluation.get("comment", "")
        notify_discord(
            f"âœ… æœ¬æ—¥ã®ãƒªã‚µãƒ¼ãƒæŠ•ç¨¿å®Œäº†\n"
            f"ãƒ†ãƒ¼ãƒ: {theme}\n"
            f"å“è³ªã‚¹ã‚³ã‚¢: {score}/100ï¼ˆ{comment}ï¼‰\n\n"
            f"---\n{draft[:1500]}\n\n"
            f"{'...(ç¶šãçœç•¥)' if len(draft) > 1500 else ''}"
        )
        log.info(f"=== æ¯æœãƒªã‚µãƒ¼ãƒå®Œäº†: ã‚¹ã‚³ã‚¢{score} ===")

        # agent-diary: æ—¥æ¬¡ã¾ã¨ã‚
        post_diary(
            f"æœ¬æ—¥ã®ãƒªã‚µãƒ¼ãƒå®Œäº†\n"
            f"ãƒ†ãƒ¼ãƒ: {theme}\n"
            f"å“è³ªã‚¹ã‚³ã‚¢: {score}/100\n"
            f"æ‰€æ„Ÿ: {comment}\n"
            f"æ˜æ—¥ã¸ã®æ”¹å–„ç‚¹: {'ç‹¬è‡ªè€ƒå¯Ÿã‚’å¢—ã‚„ã™' if isinstance(score, int) and score < 80 else 'ã“ã®ã‚¯ã‚ªãƒªãƒ†ã‚£ã‚’ç¶­æŒ'}",
            step="daily",
        )
    except Exception as e:
        log.error(f"daily_research æœªå‡¦ç†ä¾‹å¤–: {e}", exc_info=True)
        try:
            notify_discord(f"âš ï¸ daily_research ã§æœªå‡¦ç†ä¾‹å¤–ãŒç™ºç”Ÿ: {e}", is_alert=True)
        except Exception:
            pass


# â”€â”€â”€ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def weekly_memory_cleanup():
    """é€±æ¬¡ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—: TTLåˆ‡ã‚Œå‰Šé™¤ + Ollamaè¦ç´„ç”Ÿæˆ"""
    from memory_manager import MemoryManager
    try:
        mm = MemoryManager()
        mm.cleanup()
        mm.summarize_week()
        log.info("é€±æ¬¡ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
    except Exception as e:
        log.error(f"é€±æ¬¡ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¤±æ•—: {e}")


def scheduler_heartbeat():
    """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã®ç”Ÿå­˜ç¢ºèªï¼ˆ5åˆ†ã”ã¨ï¼‰ã€‚ã‚¹ãƒ¬ãƒƒãƒ‰æ•°ã‚’ãƒ­ã‚°ã«è¨˜éŒ²ã€‚"""
    thread_count = threading.active_count()
    log.info(f"ğŸ’“ heartbeat: threads={thread_count}, pid={os.getpid()}")


# â”€â”€â”€ ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if __name__ == "__main__":
    log.info("autonomous_agent èµ·å‹•")

    # Ollamaå¯ç”¨æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆIssue #1ï¼‰
    if LocalLLM.is_available():
        log.info(f"âœ… Ollama åˆ©ç”¨å¯èƒ½: {OLLAMA_URL} / ãƒ¢ãƒ‡ãƒ«: {OLLAMA_MODEL}")
        llm_status = f"ğŸ§  LLM: Ollama ({OLLAMA_MODEL}) + Claude Sonnet (ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰)"
        post_diary(f"Ollama ({OLLAMA_MODEL}) ãŒåˆ©ç”¨å¯èƒ½ã§ã™ã€‚ãƒ­ãƒ¼ã‚«ãƒ«LLMã§è»½é‡ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚", step="startup")
    else:
        log.warning(f"âš ï¸ Ollama åˆ©ç”¨ä¸å¯ã€‚Claude APIã®ã¿ã§å‹•ä½œã—ã¾ã™ã€‚")
        llm_status = "ğŸ§  LLM: Claude API ã®ã¿ï¼ˆOllamaæœªèµ·å‹•ï¼‰"
        post_diary("Ollama ãŒåˆ©ç”¨ä¸å¯ã®ãŸã‚ã€Claude APIã®ã¿ã§å‹•ä½œã—ã¾ã™ã€‚", step="startup")

    # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è¨­å®š: INTERVAL_MINUTES ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã‚Œã°ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒ«å®Ÿè¡Œ
    interval_minutes = os.getenv("INTERVAL_MINUTES")

    # APScheduler: æ˜ç¤ºçš„ãªExecutorè¨­å®šã§ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ—ãƒ¼ãƒ«å´©å£Šã‚’é˜²æ­¢
    executors = {
        "default": ThreadPoolExecutor(max_workers=10),
    }
    job_defaults = {
        "coalesce": True,          # è¤‡æ•°misfireã‚’1å›ã«çµ±åˆ
        "max_instances": 1,         # åŒä¸€ã‚¸ãƒ§ãƒ–ã®åŒæ™‚å®Ÿè¡Œé˜²æ­¢
        "misfire_grace_time": 300,  # 5åˆ†ä»¥å†…ã®misfireã¯å®Ÿè¡Œã‚’è¨±å¯
    }
    scheduler = BlockingScheduler(
        timezone="Asia/Tokyo",
        executors=executors,
        job_defaults=job_defaults,
    )

    if interval_minutes:
        interval_minutes = int(interval_minutes)
        scheduler.add_job(
            daily_research,
            trigger="interval",
            minutes=interval_minutes,
            id="daily_research",
            name=f"{interval_minutes}åˆ†ã”ã¨ãƒªã‚µãƒ¼ãƒï¼ˆãƒ†ã‚¹ãƒˆï¼‰",
        )
        schedule_desc = f"â±ï¸ {interval_minutes}åˆ†é–“éš”ï¼ˆãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼‰"
        log.info(f"ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©èµ·å‹•: {interval_minutes}åˆ†ã”ã¨ï¼ˆãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼‰")
    else:
        scheduler.add_job(
            daily_research,
            trigger="cron",
            hour=8,
            minute=0,
            id="daily_research",
            name="æ¯æœãƒªã‚µãƒ¼ãƒæŠ•ç¨¿",
        )
        schedule_desc = "ğŸ“… æ¯æœ 08:00 JST"
        log.info("ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©èµ·å‹•: æ¯æœ 08:00 JST")

    # agent-chat ãƒãƒ¼ãƒªãƒ³ã‚°: 30ç§’ã”ã¨ã«æœªå‡¦ç†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆIssue #18ï¼‰
    scheduler.add_job(
        poll_chat_messages,
        trigger="interval",
        seconds=30,
        id="poll_chat",
        name="agent-chat ãƒãƒ¼ãƒªãƒ³ã‚°",
    )
    log.info("agent-chat ãƒãƒ¼ãƒªãƒ³ã‚°: 30ç§’é–“éš”ã§èµ·å‹•")

    # é€±æ¬¡ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—: æ¯é€±æ—¥æ›œ03:00 JST
    scheduler.add_job(
        weekly_memory_cleanup,
        trigger="cron",
        day_of_week="sun",
        hour=3,
        minute=0,
        id="memory_cleanup",
        name="é€±æ¬¡ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—",
    )
    log.info("é€±æ¬¡ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—: æ¯é€±æ—¥æ›œ 03:00 JST")

    # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯: 5åˆ†ã”ã¨ã«ã‚¹ãƒ¬ãƒƒãƒ‰æ•°ã‚’ãƒ­ã‚°å‡ºåŠ›
    scheduler.add_job(
        scheduler_heartbeat,
        trigger="interval",
        minutes=5,
        id="heartbeat",
        name="ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ© heartbeat",
    )
    log.info("heartbeat: 5åˆ†é–“éš”ã§èµ·å‹•")

    # Chat HTTP ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ï¼ˆGo APIã‹ã‚‰ã®ãƒãƒ£ãƒƒãƒˆã‚’å—ã‘ä»˜ã‘ã‚‹ï¼‰
    start_chat_http_server()
    log.info(f"ãƒãƒ£ãƒƒãƒˆAPIã‚µãƒ¼ãƒãƒ¼èµ·å‹•: localhost:{AGENT_CHAT_PORT}")

    notify_discord(f"ğŸ¤– autonomous_agent ãŒèµ·å‹•ã—ã¾ã—ãŸã€‚{schedule_desc} ã«ãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œã—ã¾ã™ã€‚\n{llm_status}\nğŸ’¬ agent-chat: 30ç§’ãƒãƒ¼ãƒªãƒ³ã‚°ã§å¯¾è©±å—ä»˜ä¸­\nğŸŒ Chat API: localhost:{AGENT_CHAT_PORT}")
    post_diary("èµ·å‹•ã—ã¾ã—ãŸã€‚æ€è€ƒãƒ­ã‚°ã‚’ã“ã“ã«è¨˜éŒ²ã—ã¦ã„ãã¾ã™ã€‚", step="startup")

    # èµ·å‹•æ™‚ã«å³æ™‚å®Ÿè¡Œã™ã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
    if os.getenv("RUN_NOW") == "1":
        log.info("RUN_NOW=1 æ¤œå‡º: å³æ™‚å®Ÿè¡Œã—ã¾ã™")
        daily_research()

    # ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©: graceful shutdown
    def handle_signal(signum, frame):
        log.info(f"ã‚·ã‚°ãƒŠãƒ« {signum} å—ä¿¡ã€ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©åœæ­¢ä¸­...")
        scheduler.shutdown(wait=False)

    signal.signal(signal.SIGTERM, handle_signal)

    try:
        scheduler.start()
    except (KeyboardInterrupt, SystemExit):
        log.info("autonomous_agent åœæ­¢")
        notify_discord("ğŸ›‘ autonomous_agent ãŒåœæ­¢ã—ã¾ã—ãŸã€‚")
        post_diary("åœæ­¢ã—ã¾ã™ã€‚ã¾ãŸã­ã€‚", step="startup")
